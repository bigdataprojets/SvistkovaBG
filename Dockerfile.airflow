FROM apache/airflow:2.9.3-python3.11

USER root

# Установка Java и ps
RUN apt-get update && \
    apt-get install -y openjdk-17-jre-headless procps && \
    apt-get clean

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="$JAVA_HOME/bin:$PATH"
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-arm64
ENV PATH="$JAVA_HOME/bin:$PATH"

# Библиотеки для работы с MinIO и SparkSubmitOperator внутри Airflow
RUN python -m pip install --no-cache-dir minio==7.2.7 apache-airflow-providers-apache-spark==4.5.0 pyspark==3.5.3

# Локальные JAR для S3 (используем в spark-submit вместо скачивания из Maven)
COPY hadoop-aws-3.3.4.jar /opt/airflow/jars/hadoop-aws-3.3.4.jar
COPY aws-java-sdk-bundle-1.12.262.jar /opt/airflow/jars/aws-java-sdk-bundle-1.12.262.jar

USER airflow
